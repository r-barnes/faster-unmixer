{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sample_network_unmix as snu\n",
    "import export_rate_optimize as ero\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from matplotlib.colors import LogNorm\n",
    "import time\n",
    "\n",
    "from typing import Dict, List, Tuple, Any, Callable\n",
    "\n",
    "\n",
    "def explore_regularisation_strengths(\n",
    "    export_strength_tryer: Callable[[float], Dict[str, Any]],\n",
    "    start: float = -5,\n",
    "    stop: float = 2,\n",
    "    number: int = 8,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Explore a range of regularisation strengths and plot the results. Takes\n",
    "    as input a function that maps a regulariser strength to a dictionary of model outputs.\n",
    "    This requires defining a function for each network which is undesirable but for now it'll do\"\"\"\n",
    "    export_reg_strengths = list(np.logspace(start, stop, number))\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        outputs = pool.map(func=export_strength_tryer, iterable=export_reg_strengths)\n",
    "    # Process the outputs into a more manageable format\n",
    "    results_df = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"regulariser\": o[\"regulariser\"],\n",
    "                \"data_misfit\": o[\"data_misfit\"],\n",
    "                \"model_size\": o[\"model_size\"],\n",
    "                **o[\"export_rates\"].composition,\n",
    "            }\n",
    "            for o in outputs\n",
    "        ]\n",
    "    )\n",
    "    plt.scatter(\n",
    "        results_df[\"data_misfit\"],\n",
    "        results_df[\"model_size\"],\n",
    "        c=results_df[\"regulariser\"],\n",
    "        norm=LogNorm(),\n",
    "    )\n",
    "    plt.xlabel(\"Data misfit\")\n",
    "    plt.ylabel(\"Model size\")\n",
    "    # Plot the regulariser strength as a text label\n",
    "    for i, txt in enumerate(np.log10(results_df[\"regulariser\"])):\n",
    "        plt.annotate(np.round(txt,2), (results_df[\"data_misfit\"][i], results_df[\"model_size\"][i]))\n",
    "    cb = plt.colorbar()\n",
    "    cb.set_label(\"Regulariser strength\")\n",
    "    plt.show()\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def plot_export_rates_against_regulariser(results_df: pd.DataFrame, nodes: List[str], title: str):\n",
    "    \"\"\"Plot the export rates for each node against regulariser strength.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Regulariser strength\")\n",
    "    plt.ylabel(\"Export rate\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"logit\")\n",
    "    # Loop through the nodes in the network and plot the export rate against regulariser strength\n",
    "    for node in nodes:\n",
    "        plt.plot(\n",
    "            results_df[\"regulariser\"],\n",
    "            results_df[node],\n",
    "            label=node,\n",
    "        )\n",
    "    plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the overall sample network and load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample network\n",
    "sample_network, _ = snu.get_sample_graphs(\n",
    "    flowdirs_filename=\"data/d8.asc\",\n",
    "    sample_data_filename=\"data/sample_data.dat\",\n",
    ")\n",
    "\n",
    "# Load in observations\n",
    "obs_data = pd.read_csv(\"data/sample_data.dat\", delimiter=\" \")\n",
    "obs_data = obs_data.drop(columns=[\"Bi\", \"S\"])\n",
    "print(\"Building problem...\")\n",
    "elements = obs_data.columns[3:-5]\n",
    "source_regulariser = 10 ** (-1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the network into indidivual networks for each river"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting sample network into one for each river\n",
    "components = [\n",
    "    sample_network.subgraph(c).copy() for c in nx.weakly_connected_components(sample_network)\n",
    "]\n",
    "river_networks = {}\n",
    "for c in components:\n",
    "    root = [n for n in nx.topological_sort(c)][-1]\n",
    "    if root == \"CG039\":\n",
    "        name = \"don\"\n",
    "    elif root == \"CG088\":\n",
    "        name = \"Dee\"\n",
    "    elif root == \"CG090\":\n",
    "        name = \"Deveron\"\n",
    "    elif root == \"CG013\":\n",
    "        name = \"Tay\"\n",
    "    elif root == \"CG021\":\n",
    "        name = \"Don\"\n",
    "    river_networks[name] = c\n",
    "    plt.figure(figsize=(5, 3))  # Visualise network\n",
    "    plt.title(name)\n",
    "    snu.plot_network(c)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def network_to_problem_multielement(\n",
    "    river_network: nx.digraph,\n",
    ") -> Tuple[snu.SampleNetworkUnmixer, ero.MultiElementData]:\n",
    "    \"\"\"\n",
    "    Converts a river network into a SampleNetworkUnmixer problem and a MultiElementData object.\n",
    "    \"\"\"\n",
    "    problem = snu.SampleNetworkUnmixer(sample_network=river_network)\n",
    "    # Generate a MultiElementData object for each river stored in a dictionary\n",
    "    samples = [n for n in river_network.nodes]\n",
    "    obs = obs_data[obs_data[\"Sample.Code\"].isin(samples)]\n",
    "    multielement = ero.get_multielementdata(obs, elements)\n",
    "    return problem, multielement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deveron\n",
    "\n",
    "Now we set up the problem in the river Deveron which is small so we can assess the run-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deveron_problem, deveron_multielement = network_to_problem_multielement(river_networks[\"Deveron\"])\n",
    "deveron_nodes = [n for n in river_networks[\"Deveron\"]]\n",
    "deveron_optimiser = ero.ExportRateOptimizer(\n",
    "    source_optimiser=deveron_problem,\n",
    "    observations=deveron_multielement,\n",
    "    source_regulariser_strength=source_regulariser,\n",
    "    export_regulariser_strength=0.0,\n",
    ")\n",
    "\n",
    "\n",
    "def try_reg_strength_deveron(\n",
    "    reg_strength: float,\n",
    "):\n",
    "    \"\"\"Try a regulariser strength and return the resulting export rates and data misfit.\"\"\"\n",
    "    deveron_optimiser.regulariser_strength = reg_strength\n",
    "    deveron_optimiser.optimise()\n",
    "    return {\n",
    "        \"regulariser\": reg_strength,\n",
    "        \"export_rates\": deveron_optimiser.export_rates,\n",
    "        \"data_misfit\": deveron_optimiser.data_misfit,\n",
    "        \"model_size\": deveron_optimiser.model_size,\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Exploring regulariser strengths for Deveron...\")\n",
    "start_time = time.time()\n",
    "\n",
    "number_to_try = 33 \n",
    "deveron_results = explore_regularisation_strengths(try_reg_strength_deveron, number=number_to_try)\n",
    "end_time = time.time()\n",
    "print(\"#\" * 40)\n",
    "print(f\"Analysed results for {number_to_try} regulariser strengths\")\n",
    "print(f\"Time taken: {(end_time - start_time)/60} minutes\")\n",
    "print(\"#\" * 40)\n",
    "\n",
    "# Read in the value of \"chosen_strength\" from command line input:\n",
    "chosen_strength = input(\"Enter chosen regulariser strength for Deveron (log10 value): \")\n",
    "\n",
    "deveron_optimiser.regulariser_strength = 10 ** float(chosen_strength)\n",
    "print(\n",
    "    f\"Solving Deveron network with a regulariser strength of {deveron_optimiser.regulariser_strength}...\"\n",
    ")\n",
    "start_time = time.time()\n",
    "deveron_optimiser.optimise()\n",
    "end_time = time.time()\n",
    "deveron_export_rates = deveron_optimiser.export_rates.composition\n",
    "print(f\"Time taken: {(end_time - start_time)/60} minutes\")\n",
    "\n",
    "plot_export_rates_against_regulariser(deveron_results, deveron_nodes, \"Deveron\")\n",
    "plt.vlines(\n",
    "    x=deveron_optimiser.regulariser_strength, ymin=1e-2, ymax=1-1e-2, color=\"grey\", linestyles=\"dashed\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spey "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spey_problem, spey_multielement = network_to_problem_multielement(river_networks[\"Spey\"])\n",
    "spey_nodes = [n for n in river_networks[\"Spey\"]]\n",
    "spey_optimiser = ero.ExportRateOptimizer(\n",
    "    source_optimiser=spey_problem,\n",
    "    observations=spey_multielement,\n",
    "    source_regulariser_strength=source_regulariser,\n",
    "    export_regulariser_strength=0.0,\n",
    ")\n",
    "\n",
    "def try_reg_strength_spey(\n",
    "    reg_strength: float,\n",
    "):\n",
    "    \"\"\"Try a regulariser strength and return the resulting export rates and data misfit.\"\"\"\n",
    "    spey_optimiser.regulariser_strength = reg_strength\n",
    "    spey_optimiser.optimise()\n",
    "    return {\n",
    "        \"regulariser\": reg_strength,\n",
    "        \"export_rates\": spey_optimiser.export_rates,\n",
    "        \"data_misfit\": spey_optimiser.data_misfit,\n",
    "        \"model_size\": spey_optimiser.model_size,\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Exploring regulariser strengths for Spey...\")\n",
    "start_time = time.time()\n",
    "\n",
    "number_to_try = 33 \n",
    "spey_results = explore_regularisation_strengths(try_reg_strength_spey, number=number_to_try)\n",
    "end_time = time.time()\n",
    "print(\"#\" * 40)\n",
    "print(f\"Analysed results for {number_to_try} regulariser strengths\")\n",
    "print(f\"Time taken: {(end_time - start_time)/60} minutes\")\n",
    "print(\"#\" * 40)\n",
    "\n",
    "# Read in the value of \"chosen_strength\" from command line input:\n",
    "chosen_strength = input(\"Enter chosen regulariser strength for Spey (log10 value): \")\n",
    "\n",
    "spey_optimiser.regulariser_strength = 10 ** float(chosen_strength)\n",
    "print(\n",
    "    f\"Solving Spey network with a regulariser strength of {spey_optimiser.regulariser_strength}...\"\n",
    ")\n",
    "start_time = time.time()\n",
    "spey_optimiser.optimise()\n",
    "end_time = time.time()\n",
    "print(f\"Time taken: {(end_time - start_time)/60} minutes\")\n",
    "spey_export_rates = spey_optimiser.export_rates.composition\n",
    "\n",
    "plot_export_rates_against_regulariser(deveron_results, deveron_nodes, \"Deveron\")\n",
    "plt.vlines(\n",
    "    x=deveron_optimiser.regulariser_strength, ymin=1e-2, ymax=1-1e-2, color=\"grey\", linestyles=\"dashed\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_export_rates_against_regulariser(spey_results, spey_nodes, \"Spey\")\n",
    "plt.vlines(\n",
    "    x=spey_optimiser.regulariser_strength, ymin=0.001, ymax=0.5, color=\"grey\", linestyles=\"dashed\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "don_problem, don_multielement = network_to_problem_multielement(river_networks[\"Don\"])\n",
    "don_nodes = [n for n in river_networks[\"Don\"]]\n",
    "don_optimiser = ero.ExportRateOptimizer(\n",
    "    source_optimiser=don_problem,\n",
    "    observations=don_multielement,\n",
    "    source_regulariser_strength=source_regulariser,\n",
    "    export_regulariser_strength=0.0,\n",
    ")\n",
    "\n",
    "def try_reg_strength_don(\n",
    "    reg_strength: float,\n",
    "):\n",
    "    \"\"\"Try a regulariser strength and return the resulting export rates and data misfit.\"\"\"\n",
    "    don_optimiser.regulariser_strength = reg_strength\n",
    "    don_optimiser.optimise()\n",
    "    return {\n",
    "        \"regulariser\": reg_strength,\n",
    "        \"export_rates\": don_optimiser.export_rates,\n",
    "        \"data_misfit\": don_optimiser.data_misfit,\n",
    "        \"model_size\": don_optimiser.model_size,\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Exploring regulariser strengths for Don...\")\n",
    "start_time = time.time()\n",
    "\n",
    "number_to_try = 17 \n",
    "don_results = explore_regularisation_strengths(try_reg_strength_don, number=number_to_try)\n",
    "end_time = time.time()\n",
    "print(\"#\" * 40)\n",
    "print(f\"Analysed results for {number_to_try} regulariser strengths\")\n",
    "print(f\"Time taken: {(end_time - start_time)/60} minutes\")\n",
    "print(\"#\" * 40)\n",
    "\n",
    "# Read in the value of \"chosen_strength\" from command line input:\n",
    "chosen_strength = input(\"Enter chosen regulariser strength for Don (log10 value): \")\n",
    "\n",
    "don_optimiser.regulariser_strength = 10 ** float(chosen_strength)\n",
    "print(\n",
    "    f\"Solving Don network with a regulariser strength of {don_optimiser.regulariser_strength}...\"\n",
    ")\n",
    "start_time = time.time()\n",
    "don_optimiser.optimise()\n",
    "end_time = time.time()\n",
    "print(f\"Time taken: {(end_time - start_time)/60} minutes\")\n",
    "don_export_rates = don_optimiser.export_rates.composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_export_rates_against_regulariser(don_results, don_nodes, \"Don\")\n",
    "plt.vlines(\n",
    "    x=don_optimiser.regulariser_strength, ymin=0.001, ymax=1-0.001, color=\"grey\", linestyles=\"dashed\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tay_problem, tay_multielement = network_to_problem_multielement(river_networks[\"Tay\"])\n",
    "tay_nodes = [n for n in river_networks[\"Tay\"]]\n",
    "tay_optimiser = ero.ExportRateOptimizer(\n",
    "    source_optimiser=tay_problem,\n",
    "    observations=tay_multielement,\n",
    "    source_regulariser_strength=source_regulariser,\n",
    "    export_regulariser_strength=0.0,\n",
    ")\n",
    "\n",
    "def try_reg_strength_tay(\n",
    "    reg_strength: float,\n",
    "):\n",
    "    \"\"\"Try a regulariser strength and return the resulting export rates and data misfit.\"\"\"\n",
    "    tay_optimiser.regulariser_strength = reg_strength\n",
    "    tay_optimiser.optimise()\n",
    "    return {\n",
    "        \"regulariser\": reg_strength,\n",
    "        \"export_rates\": tay_optimiser.export_rates,\n",
    "        \"data_misfit\": tay_optimiser.data_misfit,\n",
    "        \"model_size\": tay_optimiser.model_size,\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Exploring regulariser strengths for Tay...\")\n",
    "start_time = time.time()\n",
    "\n",
    "number_to_try = 8\n",
    "tay_results = explore_regularisation_strengths(try_reg_strength_tay, number=number_to_try)\n",
    "end_time = time.time()\n",
    "print(\"#\" * 40)\n",
    "print(f\"Analysed results for {number_to_try} regulariser strengths\")\n",
    "print(f\"Time taken: {(end_time - start_time)/60} minutes\")\n",
    "print(\"#\" * 40)\n",
    "\n",
    "# Read in the value of \"chosen_strength\" from command line input:\n",
    "chosen_strength = input(\"Enter chosen regulariser strength for Tay (log10 value): \")\n",
    "\n",
    "tay_optimiser.regulariser_strength = 10 ** float(chosen_strength)\n",
    "print(\n",
    "    f\"Solving Tay network with a regulariser strength of {tay_optimiser.regulariser_strength}...\"\n",
    ")\n",
    "start_time = time.time()\n",
    "tay_optimiser.optimise()\n",
    "end_time = time.time()\n",
    "print(f\"Time taken: {(end_time - start_time)/60} minutes\")\n",
    "tay_export_rates = tay_optimiser.export_rates.composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_export_rates_against_regulariser(tay_results, tay_nodes, \"Tay\")\n",
    "plt.vlines(\n",
    "    x=tay_optimiser.regulariser_strength, ymin=1e-2, ymax=1-1e-2, color=\"grey\", linestyles=\"dashed\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dee_problem, dee_multielement = network_to_problem_multielement(river_networks[\"Dee\"])\n",
    "dee_nodes = [n for n in river_networks[\"Dee\"]]\n",
    "dee_optimiser = ero.ExportRateOptimizer(\n",
    "    source_optimiser=dee_problem,\n",
    "    observations=dee_multielement,\n",
    "    source_regulariser_strength=source_regulariser,\n",
    "    export_regulariser_strength=0.0,\n",
    ")\n",
    "\n",
    "def try_reg_strength_dee(\n",
    "    reg_strength: float,\n",
    "):\n",
    "    \"\"\"Try a regulariser strength and return the resulting export rates and data misfit.\"\"\"\n",
    "    dee_optimiser.regulariser_strength = reg_strength\n",
    "    dee_optimiser.optimise()\n",
    "    return {\n",
    "        \"regulariser\": reg_strength,\n",
    "        \"export_rates\": dee_optimiser.export_rates,\n",
    "        \"data_misfit\": dee_optimiser.data_misfit,\n",
    "        \"model_size\": dee_optimiser.model_size,\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Exploring regulariser strengths for Dee...\")\n",
    "start_time = time.time()\n",
    "\n",
    "number_to_try = 8\n",
    "dee_results = explore_regularisation_strengths(try_reg_strength_dee, number=number_to_try)\n",
    "end_time = time.time()\n",
    "print(\"#\" * 40)\n",
    "print(f\"Analysed results for {number_to_try} regulariser strengths\")\n",
    "print(f\"Time taken: {(end_time - start_time)/60} minutes\")\n",
    "print(\"#\" * 40)\n",
    "\n",
    "# Read in the value of \"chosen_strength\" from command line input:\n",
    "chosen_strength = input(\"Enter chosen regulariser strength for Dee (log10 value): \")\n",
    "\n",
    "dee_optimiser.regulariser_strength = 10 ** float(chosen_strength)\n",
    "print(\n",
    "    f\"Solving Dee network with a regulariser strength of {dee_optimiser.regulariser_strength}...\"\n",
    ")\n",
    "start_time = time.time()\n",
    "dee_optimiser.optimise()\n",
    "end_time = time.time()\n",
    "print(f\"Time taken: {(end_time - start_time)/60} minutes\")\n",
    "dee_export_rates = dee_optimiser.export_rates.composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_export_rates_against_regulariser(dee_results, dee_nodes, \"Dee\")\n",
    "plt.vlines(\n",
    "    x=dee_optimiser.regulariser_strength, ymin=1e-2, ymax=1-1e-2, color=\"grey\", linestyles=\"dashed\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring all the export rates together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply the export rates for the Dee by 0.03 (Mt/yr) - Milliman & Farnsworth\n",
    "dee_export_rates = {k: v * 0.03 for k, v in dee_export_rates.items()}\n",
    "# Multiply the don by 0.03 (Mt/yr) - Milliman & Farnsworth\n",
    "don_export_rates = {k: v * 0.03 for k, v in don_export_rates.items()}\n",
    "# Multiply the Deveron by 0.01 (Mt/yr) - Milliman & Farnsworth\n",
    "deveron_export_rates = {k: v * 0.01 for k, v in deveron_export_rates.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all the export rates into one dictionary \n",
    "all_export_rates = (spey_export_rates | don_export_rates | deveron_export_rates | tay_export_rates | dee_export_rates)\n",
    "area_dict = snu.get_unique_upstream_areas(sample_network)\n",
    "export_map = snu.get_upstream_concentration_map(areas=area_dict, upstream_preds=all_export_rates)\n",
    "export_map[export_map==0] = np.nan\n",
    "plt.imshow(export_map,norm=LogNorm(),cmap=\"viridis\"()\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "working",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
